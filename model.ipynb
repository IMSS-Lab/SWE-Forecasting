{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pz1hktPhoX2_"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoder(layers.Layer):\n",
        "    def __init__(self, emb_dim, num_heads, hidden_dim):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=emb_dim)\n",
        "        self.ffn = models.Sequential([\n",
        "            layers.Dense(hidden_dim, activation='relu'),\n",
        "            layers.Dense(emb_dim)\n",
        "        ])\n",
        "        self.layernorm1 = layers.LayerNormalization()\n",
        "        self.layernorm2 = layers.LayerNormalization()\n",
        "        self.dropout1 = layers.Dropout(0.1)\n",
        "        self.dropout2 = layers.Dropout(0.1)\n",
        "\n",
        "    def call(self, x):\n",
        "        attn_output = self.attn(x, x)\n",
        "        out1 = self.layernorm1(x + self.dropout1(attn_output))\n",
        "        ffn_output = self.ffn(out1)\n",
        "        return self.layernorm2(out1 + self.dropout2(ffn_output))\n",
        "\n",
        "class ConvLSTMCell(layers.Layer):\n",
        "    def __init__(self, hidden_dim):\n",
        "        super(ConvLSTMCell, self).__init__()\n",
        "        self.convlstm = layers.ConvLSTM2D(hidden_dim, kernel_size=3, padding='same', return_sequences=True)\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.convlstm(x)\n",
        "\n",
        "class UNetDecoderBlock(layers.Layer):\n",
        "    def __init__(self, out_channels):\n",
        "        super(UNetDecoderBlock, self).__init__()\n",
        "        self.conv = models.Sequential([\n",
        "            layers.Conv2D(out_channels, kernel_size=3, padding='same', activation='relu'),\n",
        "            layers.Conv2D(out_channels, kernel_size=3, padding='same', activation='relu')\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class PatchEmbedding(layers.Layer):\n",
        "    def __init__(self, patch_size, emb_dim):\n",
        "        super(PatchEmbedding, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.conv = layers.Conv3D(emb_dim, kernel_size=patch_size, strides=patch_size)\n",
        "\n",
        "    def call(self, x):\n",
        "        # Reshape to combine batch and time dimensions\n",
        "        batch_size, time_steps, depth, height, width, channels = tf.unstack(tf.shape(x))\n",
        "        x = tf.reshape(x, [-1, depth, height, width, channels])\n",
        "        x = self.conv(x)\n",
        "        # Reshape back to separate batch and time dimensions\n",
        "        new_depth, new_height, new_width = x.shape[1:4]\n",
        "        x = tf.reshape(x, [batch_size, time_steps, new_depth, new_height, new_width, self.emb_dim])\n",
        "        return x\n",
        "\n",
        "class SWETransUNet(models.Model):\n",
        "    def __init__(self, in_channels=3, emb_dim=384, num_heads=4, hidden_dim=512, num_layers=2, patch_size=(2,4,4)):\n",
        "        super(SWETransUNet, self).__init__()\n",
        "        self.patch_embed = PatchEmbedding(patch_size, emb_dim)\n",
        "        self.encoder = [TransformerEncoder(emb_dim, num_heads, hidden_dim) for _ in range(num_layers)]\n",
        "        self.conv_lstm = ConvLSTMCell(emb_dim)\n",
        "        self.decoder = [\n",
        "            UNetDecoderBlock(192),\n",
        "            UNetDecoderBlock(96),\n",
        "            UNetDecoderBlock(48),\n",
        "            UNetDecoderBlock(32)\n",
        "        ]\n",
        "        self.final_conv = layers.Conv2D(3, kernel_size=1)\n",
        "        self.upsample = layers.UpSampling2D(size=(2, 2))\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.patch_embed(x)\n",
        "\n",
        "        batch_size, time_steps, depth, height, width, channels = tf.unstack(tf.shape(x))\n",
        "        x = tf.reshape(x, [batch_size * time_steps * depth, height * width, channels])\n",
        "\n",
        "        for encoder_layer in self.encoder:\n",
        "            x = encoder_layer(x)\n",
        "\n",
        "        x = tf.reshape(x, [batch_size, time_steps * depth, height, width, channels])\n",
        "\n",
        "        x = self.conv_lstm(x)\n",
        "\n",
        "        x = x[:, -1]\n",
        "\n",
        "        for i, decoder_layer in enumerate(self.decoder):\n",
        "            x = decoder_layer(x)\n",
        "            if i < 2:  # Upsample twice to reach 64x64\n",
        "                x = self.upsample(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "        return x"
      ]
    }
  ]
}